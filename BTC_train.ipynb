{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amodtfx/KRLSTM/blob/main/BTC_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-colab-shell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JlKHBdKGbC4",
        "outputId": "63080dbe-55e0-49d4-c863-81bcad58ab99"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-colab-shell\n",
            "  Downloading google-colab-shell-0.2.tar.gz (4.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: google-colab-shell\n",
            "  Building wheel for google-colab-shell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-colab-shell: filename=google_colab_shell-0.2-py3-none-any.whl size=4123 sha256=951e038791bd79a52054dbb2b816e73b2c4450ee4c7b7b3cdd9dded9981e7cc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/28/39/256dc5595d46f8781c8a52a86e31754b28168b2aa15d5d68fd\n",
            "Successfully built google-colab-shell\n",
            "Installing collected packages: google-colab-shell\n",
            "Successfully installed google-colab-shell-0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the module once\n",
        "from google_colab_shell import getshell"
      ],
      "metadata": {
        "id": "xTEXA2pQGg6k"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Anytime you want to open a terminal\n",
        "\n",
        "getshell()\n",
        "\n",
        "getshell(height=400) # custom height of the terminal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "zhQFsHEDGtJ9",
        "outputId": "686172d6-1a5b-4444-8ef9-99601bfd32cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!--https://github.com/singhsidhukuldeep/Google-Colab-Shell/-->\n",
              "<!--Using JS/CSS from official sources with backups in-case :)-->\n",
              "<div id=colab_shell></div>\n",
              "<script src=\"https://code.jquery.com/jquery-latest.js\"></script>\n",
              "<script src=\"https://cdn.jsdelivr.net/npm/jquery.terminal/js/jquery.terminal.min.js\"></script>\n",
              "<link href=\"https://cdn.jsdelivr.net/npm/jquery.terminal/css/jquery.terminal.min.css\" rel=\"stylesheet\"/>\n",
              "<script>\n",
              "   $('#colab_shell').terminal(async function(command) {\n",
              "       if (command !== '') {\n",
              "           try {\n",
              "               let res = await google.colab.kernel.invokeFunction('shell', [command])\n",
              "               let out = res.data['application/json'][0]\n",
              "               this.echo(new String(out))\n",
              "           } catch(e) {\n",
              "               this.error(new String(e));\n",
              "           }\n",
              "       } else {\n",
              "           this.echo(\n",
              "             //   '>>Empty Command<<\\n'+\n",
              "             //   'If you can afford use Google Colab Pro'\n",
              "               );\n",
              "       }\n",
              "   }, {\n",
              "       greetings: 'Welcome to Google Colab Shell\\n'+\n",
              "         'If you can afford, please use Google Colab Pro ( https://colab.research.google.com/signup )\\n'+\n",
              "         '⭐ STAR the repo ⭐\\n https://github.com/singhsidhukuldeep/Google-Colab-Shell\\n\\n',\n",
              "       name: 'colab_shell',\n",
              "       height: 400,\n",
              "       prompt: '█$ colab>>\\t'\n",
              "   });\n",
              "</script>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for install package on colab worksheet!!!\n",
        "#run from kosole\n",
        "#!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
        "#!tar -xzf ta-lib-0.4.0-src.tar.gz\n",
        "#!cd ta-lib/\n",
        "#!ls\n",
        "#! ./configure\n",
        "#! make\n",
        "#! make install\n",
        "\n",
        "#### For download data\n",
        "# cd ..\n",
        "# mkdir data\n",
        "# cd data\n",
        "# end comment\n",
        "\n",
        "!!pip install ta-lib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vnoe4PWya13v",
        "outputId": "f8f4007b-2af9-4a6c-de47-1893622313cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/',\n",
              " 'Collecting ta-lib',\n",
              " '  Downloading TA-Lib-0.4.25.tar.gz (271 kB)',\n",
              " '\\x1b[?25l     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/272.0 KB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m \\x1b[32m266.2/272.0 KB\\x1b[0m \\x1b[31m9.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m272.0/272.0 KB\\x1b[0m \\x1b[31m7.0 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25h  Installing build dependencies ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Getting requirements to build wheel ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Installing backend dependencies ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Preparing metadata (pyproject.toml) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " 'Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from ta-lib) (1.21.6)',\n",
              " 'Building wheels for collected packages: ta-lib',\n",
              " '  Building wheel for ta-lib (pyproject.toml) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Created wheel for ta-lib: filename=TA_Lib-0.4.25-cp38-cp38-linux_x86_64.whl size=1820847 sha256=94b6d029aa1ee02f8767300b3c15d24509434b51592700e084c189d8b9e38f94',\n",
              " '  Stored in directory: /root/.cache/pip/wheels/da/72/bf/464831127ee8d6d9a5b76340a6a2f115182e159309dc3067ca',\n",
              " 'Successfully built ta-lib',\n",
              " 'Installing collected packages: ta-lib',\n",
              " 'Successfully installed ta-lib-0.4.25']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "from pandas import Series\n",
        "from pandas import concat\n",
        "from pandas import read_csv\n",
        "import numpy\n",
        "import talib\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Bidirectional\n",
        "import os\n",
        "import warnings"
      ],
      "metadata": {
        "id": "va_p-4E3aTH_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download data\n",
        "!wget https://raw.githubusercontent.com/Amodtfx/KRLSTM/a5d2486806ca1528903efe6510884589e2bf29c5/data/XBTEUR_2018.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_Iy_2u_1tus",
        "outputId": "992851d3-96f8-4692-f6b7-5a703799fa2c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-24 17:41:20--  https://raw.githubusercontent.com/Amodtfx/KRLSTM/a5d2486806ca1528903efe6510884589e2bf29c5/data/XBTEUR_2018.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 86621 (85K) [text/plain]\n",
            "Saving to: ‘XBTEUR_2018.csv’\n",
            "\n",
            "\rXBTEUR_2018.csv       0%[                    ]       0  --.-KB/s               \rXBTEUR_2018.csv     100%[===================>]  84.59K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-01-24 17:41:20 (5.93 MB/s) - ‘XBTEUR_2018.csv’ saved [86621/86621]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGoNyWNa18CI",
        "outputId": "be752d0e-3646-4ca0-dcec-aacb20ade134"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XBTEUR_2018.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Hide messy TensorFlow warnings\n",
        "warnings.filterwarnings(\"ignore\") \t\t#Hide messy Numpy warnings\n",
        "\n",
        "# transform series into train and test sets for supervised learning\n",
        "def prepare_data(series, n_lag, n_seq, rsi_14, mfi_14, mom_14, plus_dm_14, dx_14, cci_14, aaron_14, cmo_14, roc_14, rorc_14, will_14, bop, ad, obv, avg_price, med_price, typ_price, wcl_price, atr_14, natr_14, trange, mid_price):    \n",
        "    # rescale values to 0, 1\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    \n",
        "    values_close = series['Close'].values\n",
        "    #values_close_max = max(values_close)*2.5\n",
        "    values_close_max = 20000\n",
        "    values_close = numpy.append([values_close_max,0], values_close)      # add boundaries \n",
        "    values_close = values_close.reshape(len(values_close), 1) \n",
        "    scaled_values_close = scaler.fit_transform(values_close) \t\t\t # apply scaling \n",
        "    scaled_values_close = numpy.delete(scaled_values_close,[0,1]) \t     # remove boundaries\n",
        "\n",
        "    values_volume = series['Volume'].values\n",
        "    #values_volume_max = max(values_volume)*2.5\n",
        "    values_volume_max = 20000\n",
        "    values_volume = numpy.append([values_volume_max,0], values_volume)  # add boundaries \n",
        "    values_volume = values_volume.reshape(len(values_volume), 1) \n",
        "    scaled_values_volume = scaler.fit_transform(values_volume) \t\t    # apply scaling \n",
        "    scaled_values_volume = numpy.delete(scaled_values_volume,[0,1]) \t# remove boundaries\n",
        "    \n",
        "    values_rsi = rsi_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_rsi = scaler.fit_transform(values_rsi)\n",
        "\n",
        "    values_mfi = mfi_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_mfi = scaler.fit_transform(values_mfi)\n",
        "    \n",
        "    values_mom = mom_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_mom = scaler.fit_transform(values_mom)\n",
        "    \n",
        "    values_plus_dm = plus_dm_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_plus_dm = scaler.fit_transform(values_plus_dm)\n",
        "    \n",
        "    values_dx = dx_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_dx = scaler.fit_transform(values_dx)\n",
        "    \n",
        "    values_cci = cci_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_cci = scaler.fit_transform(values_cci) \n",
        "\n",
        "    values_aaron = aaron_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_aaron = scaler.fit_transform(values_aaron) \n",
        "    \n",
        "    values_cmo = cmo_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_cmo = scaler.fit_transform(values_cmo)\n",
        "    \n",
        "    values_roc = roc_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_roc = scaler.fit_transform(values_roc)\n",
        "    \n",
        "    values_rorc = rorc_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_rorc = scaler.fit_transform(values_rorc)\n",
        "\n",
        "    values_will = will_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_will = scaler.fit_transform(values_will)\n",
        "    \n",
        "    values_bop = bop.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_bop = scaler.fit_transform(values_bop)\n",
        "    \n",
        "    values_ad = ad.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_ad = scaler.fit_transform(values_ad)\n",
        "    \n",
        "    values_obv = obv.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_obv = scaler.fit_transform(values_obv)\n",
        "    \n",
        "    values_avg_price = avg_price.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_avg_price = scaler.fit_transform(values_avg_price)\n",
        "    \n",
        "    values_med_price = med_price.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_med_price = scaler.fit_transform(values_med_price)\n",
        "    \n",
        "    values_typ_price = typ_price.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_typ_price = scaler.fit_transform(values_typ_price)\n",
        "    \n",
        "    values_wcl_price = wcl_price.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_wcl_price = scaler.fit_transform(values_wcl_price)\n",
        "    \n",
        "    values_atr_14 = atr_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_atr_14 = scaler.fit_transform(values_atr_14)\n",
        "\n",
        "    values_natr_14 = natr_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_natr_14 = scaler.fit_transform(values_natr_14)\n",
        "\n",
        "    values_trange = trange.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_trange = scaler.fit_transform(values_trange)\n",
        "    \n",
        "    values_mid_price = mid_price.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_mid_price = scaler.fit_transform(values_mid_price)\n",
        "     \n",
        "    # transform data to be stationary\n",
        "    #--------------------------------------------\n",
        "    diff_series_close = difference(scaled_values_close, 1)\n",
        "    diff_values_close = diff_series_close.values.reshape(len(diff_series_close), 1)\n",
        "    \n",
        "    diff_series_volume = difference(scaled_values_volume, 1)\n",
        "    diff_values_volume = diff_series_volume.values.reshape(len(diff_series_volume), 1)\n",
        "  \n",
        "    diff_series_rsi = difference(scaled_values_rsi, 1)\n",
        "    diff_values_rsi = diff_series_rsi.values.reshape(len(diff_series_rsi), 1)\n",
        "    \n",
        "    diff_series_mfi = difference(scaled_values_mfi, 1)\n",
        "    diff_values_mfi = diff_series_mfi.values.reshape(len(diff_series_mfi), 1)\n",
        "    \n",
        "    diff_series_mom = difference(scaled_values_mom, 1)\n",
        "    diff_values_mom = diff_series_mom.values.reshape(len(diff_series_mom), 1)\n",
        "    \n",
        "    diff_series_plus_dm = difference(scaled_values_plus_dm, 1)\n",
        "    diff_values_plus_dm = diff_series_plus_dm.values.reshape(len(diff_series_plus_dm), 1)\n",
        "    \n",
        "    diff_series_dx = difference(scaled_values_dx, 1)\n",
        "    diff_values_dx = diff_series_dx.values.reshape(len(diff_series_dx), 1)\n",
        "    \n",
        "    diff_series_cci = difference(scaled_values_cci, 1)\n",
        "    diff_values_cci = diff_series_cci.values.reshape(len(diff_series_cci), 1) \n",
        "    \n",
        "    diff_series_aaron = difference(scaled_values_aaron, 1)\n",
        "    diff_values_aaron = diff_series_aaron.values.reshape(len(diff_series_aaron), 1) \n",
        "     \n",
        "    diff_series_cmo = difference(scaled_values_cmo, 1)\n",
        "    diff_values_cmo = diff_series_cmo.values.reshape(len(diff_series_cmo), 1)\n",
        "    \n",
        "    diff_series_roc = difference(scaled_values_roc, 1)\n",
        "    diff_values_roc = diff_series_roc.values.reshape(len(diff_series_roc), 1)\n",
        "    \n",
        "    diff_series_rorc = difference(scaled_values_rorc, 1)\n",
        "    diff_values_rorc = diff_series_rorc.values.reshape(len(diff_series_rorc), 1)\n",
        "    \n",
        "    diff_series_will = difference(scaled_values_will, 1)\n",
        "    diff_values_will = diff_series_will.values.reshape(len(diff_series_will), 1)\n",
        "    \n",
        "    diff_series_bop = difference(scaled_values_bop, 1)\n",
        "    diff_values_bop = diff_series_bop.values.reshape(len(diff_series_bop), 1)\n",
        "    \n",
        "    diff_series_ad = difference(scaled_values_ad, 1)\n",
        "    diff_values_ad = diff_series_ad.values.reshape(len(diff_series_ad), 1)\n",
        "    \n",
        "    diff_series_obv = difference(scaled_values_obv, 1)\n",
        "    diff_values_obv = diff_series_obv.values.reshape(len(diff_series_obv), 1)\n",
        "    \n",
        "    diff_series_avg_price = difference(scaled_values_avg_price, 1)\n",
        "    diff_values_avg_price = diff_series_avg_price.values.reshape(len(diff_series_avg_price), 1)\n",
        "    \n",
        "    diff_series_med_price = difference(scaled_values_med_price, 1)\n",
        "    diff_values_med_price = diff_series_med_price.values.reshape(len(diff_series_med_price), 1)\n",
        "    \n",
        "    diff_series_typ_price = difference(scaled_values_typ_price, 1)\n",
        "    diff_values_typ_price = diff_series_typ_price.values.reshape(len(diff_series_typ_price), 1)\n",
        "    \n",
        "    diff_series_wcl_price = difference(scaled_values_wcl_price, 1)\n",
        "    diff_values_wcl_price = diff_series_wcl_price.values.reshape(len(diff_series_wcl_price), 1)\n",
        "    \n",
        "    diff_series_trange = difference(scaled_values_trange, 1)\n",
        "    diff_values_trange = diff_series_trange.values.reshape(len(diff_series_trange), 1)\n",
        "\n",
        "    diff_series_natr_14 = difference(scaled_values_natr_14, 1)\n",
        "    diff_values_natr_14 = diff_series_natr_14.values.reshape(len(diff_series_natr_14), 1)\n",
        "\n",
        "    diff_series_atr_14 = difference(scaled_values_atr_14, 1)\n",
        "    diff_values_atr_14 = diff_series_atr_14.values.reshape(len(diff_series_atr_14), 1)\n",
        "    \n",
        "    diff_series_mid_price = difference(scaled_values_mid_price, 1)\n",
        "    diff_values_mid_price = diff_series_mid_price.values.reshape(len(diff_series_mid_price), 1)\n",
        "    #--------------------------------------------\n",
        "    together = numpy.concatenate((diff_values_mid_price, diff_values_atr_14, diff_values_natr_14, diff_values_trange, diff_values_wcl_price, diff_values_typ_price, diff_values_med_price, diff_values_avg_price, diff_values_obv, diff_values_ad, diff_values_bop, diff_values_will, diff_values_rorc, diff_values_roc, diff_values_cmo, diff_values_aaron, diff_values_cci, diff_values_dx, diff_values_plus_dm, diff_values_mom, diff_values_mfi, diff_values_volume, diff_values_rsi , diff_values_close), axis=1)\n",
        "    #--------------------------------------------\n",
        "    # transform into supervised learning problem X, y\n",
        "    supervised = series_to_supervised(together, n_lag, n_seq)\n",
        "    train = supervised.values\n",
        "\n",
        "    return scaler, train"
      ],
      "metadata": {
        "id": "Joeevfq5TqsT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def difference(dataset, interval=1):\n",
        "    diff = list()\n",
        "    for i in range(interval, len(dataset)):\n",
        "        value = dataset[i] - dataset[i - interval]\n",
        "        diff.append(value)\n",
        "    return Series(diff)\n"
      ],
      "metadata": {
        "id": "uiqY3y8R1BuJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i).iloc[:,-1])\n",
        "        if i == 0:\n",
        "            names += ['var(t)']\n",
        "        else:\n",
        "            names += ['var(t+%d)' % i]\n",
        "    # put it all together\n",
        "    agg = concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg\n",
        "\n"
      ],
      "metadata": {
        "id": "U6ezgWpE1IxG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_lstm(train, n_lag, n_batch, nb_epoch, n_neurons, n_neurons2, n_neurons3):\n",
        "    # reshape training into [samples, timesteps, features]\n",
        "    X, y = train[:, :-n_seq], train[:, -n_seq:]\n",
        "    X = X.reshape(X.shape[0], n_lag, n_features)\n",
        "    model = Sequential()\n",
        "    #First recurrent layer with dropout\n",
        "    model.add(Bidirectional(LSTM(n_neurons, return_sequences=True), batch_input_shape=(n_batch, X.shape[1], X.shape[2])))\n",
        "    model.add(Dropout(0.3))\n",
        "    #Second recurrent layer with dropout\n",
        "    model.add(Bidirectional(LSTM((n_neurons2), return_sequences=True)))\n",
        "    model.add(Dropout(0.3))\n",
        "    #Third recurrent layer\n",
        "    model.add(Bidirectional(LSTM(n_neurons3, return_sequences=False)))\n",
        "    #Output layer (returns the predicted value)\n",
        "    model.add(Dense(y.shape[1],activation='linear'))\n",
        "    #Set loss function and optimizer\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    # fit network\n",
        "    model.fit(X, y, epochs=nb_epoch, batch_size=n_batch, verbose=1, shuffle=False)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "ePFjoukS1Lw0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "load_data = read_csv('XBTEUR_2018.csv', header=0)"
      ],
      "metadata": {
        "id": "pusyIZZZ3EN5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configure\n",
        "n_lag = 5\t\t # okno (z kolika předchozích hodnot)\n",
        "n_seq = 3\t\t # počet predikovaných kroků t+n\n",
        "n_features = 24  # Close, Volume, RSI..\n",
        "n_epochs = 2000\n",
        "n_batch = 1\n",
        "n_neurons = 32\n",
        "n_neurons2 = 64\n",
        "n_neurons3 = 32\n",
        "rsi_n_day = 14\n",
        "\n",
        "series_data = load_data[rsi_n_day:].copy()\n",
        "series = series_data.reset_index(drop=True)\n",
        "\n",
        "rsi_14 = talib.RSI(numpy.array(load_data['Close']), rsi_n_day)  \t# Vypocet RSI //+14 hodnot\n",
        "rsi_14 = rsi_14[rsi_n_day:]\t\t\t\t\t\t\t\t\t\t    # Nan value trim\n",
        "\n",
        "mfi_14 = talib.MFI(numpy.array(load_data['Max']),numpy.array(load_data['Min']),numpy.array(load_data['Close']),numpy.array(load_data['Volume']), rsi_n_day)\n",
        "mfi_14 = mfi_14[rsi_n_day:]\t\n",
        "\n",
        "mom_14 = talib.MOM(numpy.array(load_data['Close']), rsi_n_day)\n",
        "mom_14 = mom_14[rsi_n_day:]\n",
        "\n",
        "plus_dm_14 = talib.PLUS_DM(numpy.array(load_data['Max']), numpy.array(load_data['Min']), rsi_n_day)\t\n",
        "plus_dm_14 = plus_dm_14[rsi_n_day:]\n",
        "\n",
        "dx_14 = talib.DX(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']), rsi_n_day)\n",
        "dx_14 = dx_14[rsi_n_day:]\n",
        "\n",
        "cci_14 = talib.CCI(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']), rsi_n_day)\n",
        "cci_14 = cci_14[rsi_n_day:]\n",
        "\n",
        "aaron_14 = talib.AROONOSC(numpy.array(load_data['Max']), numpy.array(load_data['Min']), rsi_n_day)\n",
        "aaron_14 = aaron_14[rsi_n_day:]\n",
        "\n",
        "cmo_14 = talib.CMO(numpy.array(load_data['Close']), rsi_n_day)\n",
        "cmo_14 = cmo_14[rsi_n_day:]\n",
        "\n",
        "roc_14 = talib.ROC(numpy.array(load_data['Close']), rsi_n_day)\n",
        "roc_14 = roc_14[rsi_n_day:]\n",
        "\n",
        "rorc_14 = talib.ROCR(numpy.array(load_data['Close']), rsi_n_day)\n",
        "rorc_14 = rorc_14[rsi_n_day:]\n",
        "\n",
        "will_14 = talib.WILLR(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']), rsi_n_day)\n",
        "will_14 = will_14[rsi_n_day:]\n",
        "\n",
        "bop = talib.BOP(numpy.array(load_data['Open']), numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']))\n",
        "bop = bop[rsi_n_day:]\n",
        "\n",
        "ad = talib.AD(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']), numpy.array(load_data['Volume']))\n",
        "ad = ad[rsi_n_day:]\n",
        "\n",
        "obv = talib.OBV(numpy.array(load_data['Close']), numpy.array(load_data['Volume']))\n",
        "obv = obv[rsi_n_day:]\n",
        "\n",
        "avg_price = talib.AVGPRICE(numpy.array(load_data['Open']), numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']))\n",
        "avg_price = avg_price[rsi_n_day:]\n",
        "\n",
        "med_price = talib.MEDPRICE(numpy.array(load_data['Max']), numpy.array(load_data['Min']))\n",
        "med_price = med_price[rsi_n_day:]\n",
        "\n",
        "typ_price = talib.TYPPRICE(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']))\n",
        "typ_price = typ_price[rsi_n_day:]\n",
        "\n",
        "wcl_price = talib.WCLPRICE(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']))\n",
        "wcl_price = wcl_price[rsi_n_day:]\n",
        "\n",
        "atr_14 = talib.ATR(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']), rsi_n_day)\n",
        "atr_14 = atr_14[rsi_n_day:]\n",
        "\n",
        "natr_14 = talib.NATR(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']), rsi_n_day)\n",
        "natr_14 = natr_14[rsi_n_day:]\n",
        "\n",
        "trange = talib.TRANGE(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']))\n",
        "trange = trange[rsi_n_day:]\n",
        "\n",
        "mid_price = talib.MIDPRICE(numpy.array(load_data['Max']), numpy.array(load_data['Min']), rsi_n_day)\n",
        "mid_price = mid_price[rsi_n_day:]\n"
      ],
      "metadata": {
        "id": "6Aphuurn1Pzv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler, train = prepare_data(series, n_lag, n_seq, rsi_14, mfi_14, mom_14, plus_dm_14, dx_14, cci_14, aaron_14, cmo_14, roc_14, rorc_14, will_14, bop, ad, obv, avg_price, med_price, typ_price, wcl_price, atr_14, natr_14, trange, mid_price)\n"
      ],
      "metadata": {
        "id": "y5AAJbYE6gTR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = fit_lstm(train, n_lag, n_batch, n_epochs, n_neurons, n_neurons2, n_neurons3)\n",
        "\n"
      ],
      "metadata": {
        "id": "8BTulofi6gR4",
        "outputId": "663b2189-426d-4c54-e81e-e4e305049896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-4c98500010a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_lag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neurons2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neurons3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-e77d79129adf>\u001b[0m in \u001b[0;36mfit_lstm\u001b[0;34m(train, n_lag, n_batch, nb_epoch, n_neurons, n_neurons2, n_neurons3)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# fit network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"BTC_basic.h5\", overwrite=True)"
      ],
      "metadata": {
        "id": "Gurkr81f6tq6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}