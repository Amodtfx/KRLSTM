{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install google-colab-shell"
      ],
      "metadata": {
        "id": "-JlKHBdKGbC4",
        "outputId": "f157864f-902a-45f1-9546-0a0f4bf80f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (0.38.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the module once\n",
        "from google_colab_shell import getshell"
      ],
      "metadata": {
        "id": "xTEXA2pQGg6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Anytime you want to open a terminal\n",
        "\n",
        "getshell()\n",
        "\n",
        "getshell(height=400) # custom height of the terminal"
      ],
      "metadata": {
        "id": "zhQFsHEDGtJ9",
        "outputId": "765ee50d-824f-4fa5-9510-72c1d7a4fc60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!--https://github.com/singhsidhukuldeep/Google-Colab-Shell/-->\n",
              "<!--Using JS/CSS from official sources with backups in-case :)-->\n",
              "<div id=colab_shell></div>\n",
              "<script src=\"https://code.jquery.com/jquery-latest.js\"></script>\n",
              "<script src=\"https://cdn.jsdelivr.net/npm/jquery.terminal/js/jquery.terminal.min.js\"></script>\n",
              "<link href=\"https://cdn.jsdelivr.net/npm/jquery.terminal/css/jquery.terminal.min.css\" rel=\"stylesheet\"/>\n",
              "<script>\n",
              "   $('#colab_shell').terminal(async function(command) {\n",
              "       if (command !== '') {\n",
              "           try {\n",
              "               let res = await google.colab.kernel.invokeFunction('shell', [command])\n",
              "               let out = res.data['application/json'][0]\n",
              "               this.echo(new String(out))\n",
              "           } catch(e) {\n",
              "               this.error(new String(e));\n",
              "           }\n",
              "       } else {\n",
              "           this.echo(\n",
              "             //   '>>Empty Command<<\\n'+\n",
              "             //   'If you can afford use Google Colab Pro'\n",
              "               );\n",
              "       }\n",
              "   }, {\n",
              "       greetings: 'Welcome to Google Colab Shell\\n'+\n",
              "         'If you can afford, please use Google Colab Pro ( https://colab.research.google.com/signup )\\n'+\n",
              "         '⭐ STAR the repo ⭐\\n https://github.com/singhsidhukuldeep/Google-Colab-Shell\\n\\n',\n",
              "       name: 'colab_shell',\n",
              "       height: 400,\n",
              "       prompt: '█$ colab>>\\t'\n",
              "   });\n",
              "</script>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for install package on colab worksheet!!!\n",
        "#!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
        "#!tar -xzf ta-lib-0.4.0-src.tar.gz\n",
        "#!cd ta-lib/\n",
        "#!ls\n",
        "#! ./configure\n",
        "#! make\n",
        "#! make install\n",
        "# end comment"
      ],
      "metadata": {
        "id": "Vnoe4PWya13v",
        "outputId": "8bb12b31-9dd8-4929-e405-b1f839b32c8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aclocal.m4\tconfig.log     HISTORY.TXT  Makefile.am       ta-lib.dpkg\n",
            "autogen.sh\tconfig.status  include\t    Makefile.in       ta-lib.dpkg.in\n",
            "autom4te.cache\tconfig.sub     install-sh   missing\t      ta-lib.spec\n",
            "bin\t\tconfigure      libtool\t    src\t\t      ta-lib.spec.in\n",
            "CHANGELOG.TXT\tconfigure.in   ltmain.sh    ta-lib-config\n",
            "config.guess\tdepcomp        Makefile     ta-lib-config.in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "from pandas import Series\n",
        "from pandas import concat\n",
        "from pandas import read_csv\n",
        "import numpy\n",
        "import talib\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Bidirectional\n",
        "import os\n",
        "import warnings"
      ],
      "metadata": {
        "id": "va_p-4E3aTH_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Hide messy TensorFlow warnings\n",
        "warnings.filterwarnings(\"ignore\") \t\t#Hide messy Numpy warnings\n",
        "\n",
        "# transform series into train and test sets for supervised learning\n",
        "def prepare_data(series, n_lag, n_seq, rsi_14, mfi_14, mom_14, plus_dm_14, dx_14, cci_14, aaron_14, cmo_14, roc_14, rorc_14, will_14, bop, ad, obv, avg_price, med_price, typ_price, wcl_price, atr_14, natr_14, trange, mid_price):    \n",
        "    # rescale values to 0, 1\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    \n",
        "    values_close = series['Close'].values\n",
        "    #values_close_max = max(values_close)*2.5\n",
        "    values_close_max = 20000\n",
        "    values_close = numpy.append([values_close_max,0], values_close)      # add boundaries \n",
        "    values_close = values_close.reshape(len(values_close), 1) \n",
        "    scaled_values_close = scaler.fit_transform(values_close) \t\t\t # apply scaling \n",
        "    scaled_values_close = numpy.delete(scaled_values_close,[0,1]) \t     # remove boundaries\n",
        "\n",
        "    values_volume = series['Volume'].values\n",
        "    #values_volume_max = max(values_volume)*2.5\n",
        "    values_volume_max = 20000\n",
        "    values_volume = numpy.append([values_volume_max,0], values_volume)  # add boundaries \n",
        "    values_volume = values_volume.reshape(len(values_volume), 1) \n",
        "    scaled_values_volume = scaler.fit_transform(values_volume) \t\t    # apply scaling \n",
        "    scaled_values_volume = numpy.delete(scaled_values_volume,[0,1]) \t# remove boundaries\n",
        "    \n",
        "    values_rsi = rsi_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_rsi = scaler.fit_transform(values_rsi)\n",
        "\n",
        "    values_mfi = mfi_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_mfi = scaler.fit_transform(values_mfi)\n",
        "    \n",
        "    values_mom = mom_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_mom = scaler.fit_transform(values_mom)\n",
        "    \n",
        "    values_plus_dm = plus_dm_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_plus_dm = scaler.fit_transform(values_plus_dm)\n",
        "    \n",
        "    values_dx = dx_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_dx = scaler.fit_transform(values_dx)\n",
        "    \n",
        "    values_cci = cci_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_cci = scaler.fit_transform(values_cci) \n",
        "\n",
        "    values_aaron = aaron_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_aaron = scaler.fit_transform(values_aaron) \n",
        "    \n",
        "    values_cmo = cmo_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_cmo = scaler.fit_transform(values_cmo)\n",
        "    \n",
        "    values_roc = roc_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_roc = scaler.fit_transform(values_roc)\n",
        "    \n",
        "    values_rorc = rorc_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_rorc = scaler.fit_transform(values_rorc)\n",
        "\n",
        "    values_will = will_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_will = scaler.fit_transform(values_will)\n",
        "    \n",
        "    values_bop = bop.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_bop = scaler.fit_transform(values_bop)\n",
        "    \n",
        "    values_ad = ad.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_ad = scaler.fit_transform(values_ad)\n",
        "    \n",
        "    values_obv = obv.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_obv = scaler.fit_transform(values_obv)\n",
        "    \n",
        "    values_avg_price = avg_price.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_avg_price = scaler.fit_transform(values_avg_price)\n",
        "    \n",
        "    values_med_price = med_price.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_med_price = scaler.fit_transform(values_med_price)\n",
        "    \n",
        "    values_typ_price = typ_price.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_typ_price = scaler.fit_transform(values_typ_price)\n",
        "    \n",
        "    values_wcl_price = wcl_price.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_wcl_price = scaler.fit_transform(values_wcl_price)\n",
        "    \n",
        "    values_atr_14 = atr_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_atr_14 = scaler.fit_transform(values_atr_14)\n",
        "\n",
        "    values_natr_14 = natr_14.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_natr_14 = scaler.fit_transform(values_natr_14)\n",
        "\n",
        "    values_trange = trange.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_trange = scaler.fit_transform(values_trange)\n",
        "    \n",
        "    values_mid_price = mid_price.reshape(len(scaled_values_close), 1)\n",
        "    scaled_values_mid_price = scaler.fit_transform(values_mid_price)\n",
        "     \n",
        "    # transform data to be stationary\n",
        "    #--------------------------------------------\n",
        "    diff_series_close = difference(scaled_values_close, 1)\n",
        "    diff_values_close = diff_series_close.values.reshape(len(diff_series_close), 1)\n",
        "    \n",
        "    diff_series_volume = difference(scaled_values_volume, 1)\n",
        "    diff_values_volume = diff_series_volume.values.reshape(len(diff_series_volume), 1)\n",
        "  \n",
        "    diff_series_rsi = difference(scaled_values_rsi, 1)\n",
        "    diff_values_rsi = diff_series_rsi.values.reshape(len(diff_series_rsi), 1)\n",
        "    \n",
        "    diff_series_mfi = difference(scaled_values_mfi, 1)\n",
        "    diff_values_mfi = diff_series_mfi.values.reshape(len(diff_series_mfi), 1)\n",
        "    \n",
        "    diff_series_mom = difference(scaled_values_mom, 1)\n",
        "    diff_values_mom = diff_series_mom.values.reshape(len(diff_series_mom), 1)\n",
        "    \n",
        "    diff_series_plus_dm = difference(scaled_values_plus_dm, 1)\n",
        "    diff_values_plus_dm = diff_series_plus_dm.values.reshape(len(diff_series_plus_dm), 1)\n",
        "    \n",
        "    diff_series_dx = difference(scaled_values_dx, 1)\n",
        "    diff_values_dx = diff_series_dx.values.reshape(len(diff_series_dx), 1)\n",
        "    \n",
        "    diff_series_cci = difference(scaled_values_cci, 1)\n",
        "    diff_values_cci = diff_series_cci.values.reshape(len(diff_series_cci), 1) \n",
        "    \n",
        "    diff_series_aaron = difference(scaled_values_aaron, 1)\n",
        "    diff_values_aaron = diff_series_aaron.values.reshape(len(diff_series_aaron), 1) \n",
        "     \n",
        "    diff_series_cmo = difference(scaled_values_cmo, 1)\n",
        "    diff_values_cmo = diff_series_cmo.values.reshape(len(diff_series_cmo), 1)\n",
        "    \n",
        "    diff_series_roc = difference(scaled_values_roc, 1)\n",
        "    diff_values_roc = diff_series_roc.values.reshape(len(diff_series_roc), 1)\n",
        "    \n",
        "    diff_series_rorc = difference(scaled_values_rorc, 1)\n",
        "    diff_values_rorc = diff_series_rorc.values.reshape(len(diff_series_rorc), 1)\n",
        "    \n",
        "    diff_series_will = difference(scaled_values_will, 1)\n",
        "    diff_values_will = diff_series_will.values.reshape(len(diff_series_will), 1)\n",
        "    \n",
        "    diff_series_bop = difference(scaled_values_bop, 1)\n",
        "    diff_values_bop = diff_series_bop.values.reshape(len(diff_series_bop), 1)\n",
        "    \n",
        "    diff_series_ad = difference(scaled_values_ad, 1)\n",
        "    diff_values_ad = diff_series_ad.values.reshape(len(diff_series_ad), 1)\n",
        "    \n",
        "    diff_series_obv = difference(scaled_values_obv, 1)\n",
        "    diff_values_obv = diff_series_obv.values.reshape(len(diff_series_obv), 1)\n",
        "    \n",
        "    diff_series_avg_price = difference(scaled_values_avg_price, 1)\n",
        "    diff_values_avg_price = diff_series_avg_price.values.reshape(len(diff_series_avg_price), 1)\n",
        "    \n",
        "    diff_series_med_price = difference(scaled_values_med_price, 1)\n",
        "    diff_values_med_price = diff_series_med_price.values.reshape(len(diff_series_med_price), 1)\n",
        "    \n",
        "    diff_series_typ_price = difference(scaled_values_typ_price, 1)\n",
        "    diff_values_typ_price = diff_series_typ_price.values.reshape(len(diff_series_typ_price), 1)\n",
        "    \n",
        "    diff_series_wcl_price = difference(scaled_values_wcl_price, 1)\n",
        "    diff_values_wcl_price = diff_series_wcl_price.values.reshape(len(diff_series_wcl_price), 1)\n",
        "    \n",
        "    diff_series_trange = difference(scaled_values_trange, 1)\n",
        "    diff_values_trange = diff_series_trange.values.reshape(len(diff_series_trange), 1)\n",
        "\n",
        "    diff_series_natr_14 = difference(scaled_values_natr_14, 1)\n",
        "    diff_values_natr_14 = diff_series_natr_14.values.reshape(len(diff_series_natr_14), 1)\n",
        "\n",
        "    diff_series_atr_14 = difference(scaled_values_atr_14, 1)\n",
        "    diff_values_atr_14 = diff_series_atr_14.values.reshape(len(diff_series_atr_14), 1)\n",
        "    \n",
        "    diff_series_mid_price = difference(scaled_values_mid_price, 1)\n",
        "    diff_values_mid_price = diff_series_mid_price.values.reshape(len(diff_series_mid_price), 1)\n",
        "    #--------------------------------------------\n",
        "    together = numpy.concatenate((diff_values_mid_price, diff_values_atr_14, diff_values_natr_14, diff_values_trange, diff_values_wcl_price, diff_values_typ_price, diff_values_med_price, diff_values_avg_price, diff_values_obv, diff_values_ad, diff_values_bop, diff_values_will, diff_values_rorc, diff_values_roc, diff_values_cmo, diff_values_aaron, diff_values_cci, diff_values_dx, diff_values_plus_dm, diff_values_mom, diff_values_mfi, diff_values_volume, diff_values_rsi , diff_values_close), axis=1)\n",
        "    #--------------------------------------------\n",
        "    # transform into supervised learning problem X, y\n",
        "    supervised = series_to_supervised(together, n_lag, n_seq)\n",
        "    train = supervised.values\n",
        "\n",
        "    return scaler, train\n",
        "\n",
        "def difference(dataset, interval=1):\n",
        "    diff = list()\n",
        "    for i in range(interval, len(dataset)):\n",
        "        value = dataset[i] - dataset[i - interval]\n",
        "        diff.append(value)\n",
        "    return Series(diff)\n",
        "\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i).iloc[:,-1])\n",
        "        if i == 0:\n",
        "            names += ['var(t)']\n",
        "        else:\n",
        "            names += ['var(t+%d)' % i]\n",
        "    # put it all together\n",
        "    agg = concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg\n",
        "\n",
        "def fit_lstm(train, n_lag, n_batch, nb_epoch, n_neurons, n_neurons2, n_neurons3):\n",
        "    # reshape training into [samples, timesteps, features]\n",
        "    X, y = train[:, :-n_seq], train[:, -n_seq:]\n",
        "    X = X.reshape(X.shape[0], n_lag, n_features)\n",
        "    model = Sequential()\n",
        "    #First recurrent layer with dropout\n",
        "    model.add(Bidirectional(LSTM(n_neurons, return_sequences=True), batch_input_shape=(n_batch, X.shape[1], X.shape[2])))\n",
        "    model.add(Dropout(0.3))\n",
        "    #Second recurrent layer with dropout\n",
        "    model.add(Bidirectional(LSTM((n_neurons2), return_sequences=True)))\n",
        "    model.add(Dropout(0.3))\n",
        "    #Third recurrent layer\n",
        "    model.add(Bidirectional(LSTM(n_neurons3, return_sequences=False)))\n",
        "    #Output layer (returns the predicted value)\n",
        "    model.add(Dense(y.shape[1],activation='linear'))\n",
        "    #Set loss function and optimizer\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    # fit network\n",
        "    model.fit(X, y, epochs=nb_epoch, batch_size=n_batch, verbose=1, shuffle=False)\n",
        "    return model\n",
        "\n",
        "# load dataset\n",
        "load_data = read_csv('data/csv/XXBTZEUR_2017.csv', header=0)\n",
        "\n",
        "# configure\n",
        "n_lag = 5\t\t # okno (z kolika předchozích hodnot)\n",
        "n_seq = 3\t\t # počet predikovaných kroků t+n\n",
        "n_features = 24  # Close, Volume, RSI..\n",
        "n_epochs = 2000\n",
        "n_batch = 1\n",
        "n_neurons = 32\n",
        "n_neurons2 = 64\n",
        "n_neurons3 = 32\n",
        "rsi_n_day = 14\n",
        "\n",
        "series_data = load_data[rsi_n_day:].copy()\n",
        "series = series_data.reset_index(drop=True)\n",
        "\n",
        "rsi_14 = talib.RSI(numpy.array(load_data['Close']), rsi_n_day)  \t# Vypocet RSI //+14 hodnot\n",
        "rsi_14 = rsi_14[rsi_n_day:]\t\t\t\t\t\t\t\t\t\t    # Nan value trim\n",
        "\n",
        "mfi_14 = talib.MFI(numpy.array(load_data['Max']),numpy.array(load_data['Min']),numpy.array(load_data['Close']),numpy.array(load_data['Volume']), rsi_n_day)\n",
        "mfi_14 = mfi_14[rsi_n_day:]\t\n",
        "\n",
        "mom_14 = talib.MOM(numpy.array(load_data['Close']), rsi_n_day)\n",
        "mom_14 = mom_14[rsi_n_day:]\n",
        "\n",
        "plus_dm_14 = talib.PLUS_DM(numpy.array(load_data['Max']), numpy.array(load_data['Min']), rsi_n_day)\t\n",
        "plus_dm_14 = plus_dm_14[rsi_n_day:]\n",
        "\n",
        "dx_14 = talib.DX(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']), rsi_n_day)\n",
        "dx_14 = dx_14[rsi_n_day:]\n",
        "\n",
        "cci_14 = talib.CCI(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']), rsi_n_day)\n",
        "cci_14 = cci_14[rsi_n_day:]\n",
        "\n",
        "aaron_14 = talib.AROONOSC(numpy.array(load_data['Max']), numpy.array(load_data['Min']), rsi_n_day)\n",
        "aaron_14 = aaron_14[rsi_n_day:]\n",
        "\n",
        "cmo_14 = talib.CMO(numpy.array(load_data['Close']), rsi_n_day)\n",
        "cmo_14 = cmo_14[rsi_n_day:]\n",
        "\n",
        "roc_14 = talib.ROC(numpy.array(load_data['Close']), rsi_n_day)\n",
        "roc_14 = roc_14[rsi_n_day:]\n",
        "\n",
        "rorc_14 = talib.ROCR(numpy.array(load_data['Close']), rsi_n_day)\n",
        "rorc_14 = rorc_14[rsi_n_day:]\n",
        "\n",
        "will_14 = talib.WILLR(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']), rsi_n_day)\n",
        "will_14 = will_14[rsi_n_day:]\n",
        "\n",
        "bop = talib.BOP(numpy.array(load_data['Open']), numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']))\n",
        "bop = bop[rsi_n_day:]\n",
        "\n",
        "ad = talib.AD(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']), numpy.array(load_data['Volume']))\n",
        "ad = ad[rsi_n_day:]\n",
        "\n",
        "obv = talib.OBV(numpy.array(load_data['Close']), numpy.array(load_data['Volume']))\n",
        "obv = obv[rsi_n_day:]\n",
        "\n",
        "avg_price = talib.AVGPRICE(numpy.array(load_data['Open']), numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']))\n",
        "avg_price = avg_price[rsi_n_day:]\n",
        "\n",
        "med_price = talib.MEDPRICE(numpy.array(load_data['Max']), numpy.array(load_data['Min']))\n",
        "med_price = med_price[rsi_n_day:]\n",
        "\n",
        "typ_price = talib.TYPPRICE(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']))\n",
        "typ_price = typ_price[rsi_n_day:]\n",
        "\n",
        "wcl_price = talib.WCLPRICE(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']))\n",
        "wcl_price = wcl_price[rsi_n_day:]\n",
        "\n",
        "atr_14 = talib.ATR(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']), rsi_n_day)\n",
        "atr_14 = atr_14[rsi_n_day:]\n",
        "\n",
        "natr_14 = talib.NATR(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']), rsi_n_day)\n",
        "natr_14 = natr_14[rsi_n_day:]\n",
        "\n",
        "trange = talib.TRANGE(numpy.array(load_data['Max']), numpy.array(load_data['Min']), numpy.array(load_data['Close']))\n",
        "trange = trange[rsi_n_day:]\n",
        "\n",
        "mid_price = talib.MIDPRICE(numpy.array(load_data['Max']), numpy.array(load_data['Min']), rsi_n_day)\n",
        "mid_price = mid_price[rsi_n_day:]\n",
        "\n",
        "scaler, train = prepare_data(series, n_lag, n_seq, rsi_14, mfi_14, mom_14, plus_dm_14, dx_14, cci_14, aaron_14, cmo_14, roc_14, rorc_14, will_14, bop, ad, obv, avg_price, med_price, typ_price, wcl_price, atr_14, natr_14, trange, mid_price)\n",
        "model = fit_lstm(train, n_lag, n_batch, n_epochs, n_neurons, n_neurons2, n_neurons3)\n",
        "\n",
        "model.save(\"BTC_basic.h5\", overwrite=True)"
      ],
      "metadata": {
        "id": "Joeevfq5TqsT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}